{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tensorflow1.0 에 있는 wide_n_deep_tutorial.py 를 분석해 보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 텐서플로우 공식[문서](https://www.tensorflow.org/tutorials/wide_and_deep)에 나와있는 [소스](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py)를 분석하였습니다. [한글번역](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/wide_and_deep/)도 있으니 자세한 사항에 대해서는 해당 페이지들을 참고해 주세요.\n",
    "\n",
    "* 원본 소스에 약간의 주석과 python 3.6에서 안돌아가는 부분이 있어서 살짝 변경하였습니다.[변경소스](https://github.com/SSaMKJ/study201702/blob/master/com/ssamkj/py/wide_n_deep/wide_n_deep_tutorial.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"wide_n_deep.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* wide 모델은 많은 수의 가능한 특징값을 가진 분류적 특징과 crossed feature columns 으로된 리니어한 모델입니다.\n",
    "* crossed feature columns란 리니어 모델들은 독립적인 가중치를 각각의 특징에 할당하기 때문에 특정 조합의 상대적인 중요성을 알 수 없습니다. 그리하여 여러 특징들이 있을 때 상관이 깊은 특징들을 연결을 해 주어 각각 크로스된 특징들을 하나의 특징 처럼 사용할 수 있게 해 줍니다. 그리하여 특징들간의 상호작용들을 효율적으로 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* deep 모델은 feedforward neural network로 노드들이 서로 연결되어 있는데, RNN과는 다르게 순환 모양은 아닙니다.\n",
    "* 정보를 한 방향으로 계속해서 보내는 방식입니다. feed-forward의 장점은 일반화가 잘 된다는 장점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"Feed_forward_neural_net.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 이 wide 모델의 장점과 deep 모델의 장점을 합친 것이 wide_n_deep model 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 자세한 정의는 해당 문서를 보시면 되고, 저는 소스 레벨단에서 로직을 설명하겠습니다.\n",
    "* 공식 문서와는 다르게 흐름을 파악할 수 있게 순서를 변경해서 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 우선은 import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 원 소스에 보면 tempfile이 있으나 여기서는 사용하지 않을 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "  parser.add_argument(\n",
    "      \"--model_dir\",\n",
    "      type=str,\n",
    "      default=\"./model\",\n",
    "      help=\"Base directory for output models.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--model_type\",\n",
    "      type=str,\n",
    "      default=\"wide_n_deep\",\n",
    "      help=\"Valid model types: {'wide', 'deep', 'wide_n_deep'}.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--train_steps\",\n",
    "      type=int,\n",
    "      default=200,\n",
    "      help=\"Number of training steps.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--train_data\",\n",
    "      type=str,\n",
    "      default=\"./data/training_data.csv\",\n",
    "      help=\"Path to the training data.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--test_data\",\n",
    "      type=str,\n",
    "      default=\"./data/test_data.csv\",\n",
    "      help=\"Path to the test data.\"\n",
    "  )\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* parser에 값들이 추가 되었고, 그 값들이 FLAGS에 들어간 점을 눈여겨 보세요.\n",
    "* FLAG는 환경설정 값으로 계속해서 사용됩니다.\n",
    "```\n",
    "  parser.add_argument(\n",
    "      \"--model_dir\",\n",
    "      type=str,\n",
    "      default=\"./model\",\n",
    "      help=\"Base directory for output models.\"\n",
    "  )\n",
    "```  \n",
    "* argument로 --model_dir=디렉토리 이렇게 들어오다면 값이 '디렉토리'로 들어가고, argument가 없다면 default 값이 사용되는 것 입니다.\n",
    "* 꺼내 쓸 때는 FLAG.model_dir 로 쓸 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  train_and_eval(FLAGS.model_dir, FLAGS.model_type, FLAGS.train_steps,\n",
    "                 FLAGS.train_data, FLAGS.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* argument 에서 설정된 값이 train_and_eval 로 전달됩니다.\n",
    "* FLAGS에 있는 값은 위에서 argument를 정할 때 들어갔습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## train_and_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model_dir, model_type, train_steps, train_data, test_data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Train and evaluate the model.\"\"\"\n",
    "  train_file_name, test_file_name = maybe_download(train_data, test_data)\n",
    "  df_train = pd.read_csv(\n",
    "      tf.gfile.Open(train_file_name),\n",
    "      names=COLUMNS,\n",
    "      skipinitialspace=True,\n",
    "      engine=\"python\")\n",
    "  df_test = pd.read_csv(\n",
    "      tf.gfile.Open(test_file_name),\n",
    "      names=COLUMNS,\n",
    "      skipinitialspace=True,\n",
    "      skiprows=1,\n",
    "      engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* maybe_download 는 데이터를 다운 받는 함수이고 이후에 나타납니다.\n",
    "* pd는 panda라이브러리입니다. pd로 csv파일을 읽습니다.\n",
    "* COLUMNS 는 문자들이 들어있는 배열입니다.\n",
    "* csv파일에 comma(,)로 구분된 각 컬럼에 순서 대로 이름을 매칭시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove NaN elements\n",
    "  df_train = df_train.dropna(how='any', axis=0)\n",
    "  df_test = df_test.dropna(how='any', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* [dropna](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html#) 에 전달된 값을 보면 axis가 0이거나 1일 수 있는데, 0이면 row단위로 없는 값을 제거 한 뒤 리턴하고, 1이면 column이 빈 것을 제거하로 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train[LABEL_COLUMN] = (\n",
    "      df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "\n",
    "  df_test[LABEL_COLUMN] = (\n",
    "      df_test[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* LABEL_COLUMN 에는 y값으로 사용할 컬럼명이 들어가 있습니다.\n",
    "* panda (pd) 에서 리턴해준 df_train에서 이름이 \"income_bracket\" 것을 찾아 \">50K\"가 있으면 1 없으면 0으로 값을 넣어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_dir = tempfile.mkdtemp() if not model_dir else model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 조건문입니다. \n",
    "* 만약 model_dir이 None이거나 False이면 tempfile.mkdtemp()를 호출하여 model_dir에 넣어주고, 그렇지 않다면 model_dir을 넣어 줍니다.\n",
    "* 즉, model_dir이 None이거나 False인지를 체크해서 model_dir의 값을 넣어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = build_estimator(model_dir, model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 모델을 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\n",
    "  results = m.evaluate(input_fn=lambda: input_fn(df_test), steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* m.fit 모델을 학습 시킵니다. input_fn함수에 df_train을 넣어줍니다.\n",
    "* m.evaluate는 학습된 모델을 평가합니다.\n",
    "* steps 는 학습할 횟수를 정한 것으로 None이 들어가면 영원히 돌아가니 주의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = m.evaluate(input_fn=lambda: input_fn(df_test), steps=1)\n",
    "  for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 출력 값은 아래처럼 나왔습니다. 돌릴 때 마다 약간씩 다르게 나타납니다.\n",
    "* accuracy: 0.818193\n",
    "* accuracy/baseline_label_mean: 0.236226\n",
    "* accuracy/threshold_0.500000_mean: 0.818193\n",
    "* auc: 0.861029\n",
    "* global_step: 202\n",
    "* labels/actual_label_mean: 0.236226\n",
    "* labels/prediction_mean: 0.32576\n",
    "* loss: 1.24135\n",
    "* precision/positive_threshold_0.500000_mean: 0.611251\n",
    "* recall/positive_threshold_0.500000_mean: 0.632865"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## build_estimator - 모델 만들기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 사용할 특징(feature)들을 정의 한 뒤 wide column과 deep column을 정의하고, 모델을 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_estimator(model_dir, model_type):\n",
    "  \"\"\"Build an estimator.\"\"\"\n",
    "  # Sparse base columns.\n",
    "\n",
    "  '''\n",
    "  몇 개 안되는 값일 때... 즉 몇 가지 케이스로 정해진 경우\n",
    "  '''\n",
    "  gender = tf.contrib.layers.sparse_column_with_keys(column_name=\"gender\",\n",
    "                                                     keys=[\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* sparse column들을 만드는데, 몇 가지 타입이 있습니다.\n",
    "* [sparse_column_with_keys](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/sparse_column_with_keys) 는 값이 몇 가지로 한정되어 있을 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  해쉬 값으로 읽음.\n",
    "  '''\n",
    "  education = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"education\", hash_bucket_size=1000)\n",
    "  relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"relationship\", hash_bucket_size=100)\n",
    "  workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"workclass\", hash_bucket_size=100)\n",
    "  occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"occupation\", hash_bucket_size=1000)\n",
    "  native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "      \"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* [sparse_column_with_hash_bucket](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/sparse_column_with_hash_bucket) 는 문자열로 된 것들을 hash 값으로 변경해서 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Continuous base columns.\n",
    "  '''\n",
    "  숫자 형.\n",
    "  '''\n",
    "  age = tf.contrib.layers.real_valued_column(\"age\")\n",
    "  education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
    "  capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
    "  capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
    "  hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* [real_valued_column](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/real_valued_column)는 숫자형 데이터 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transformations.\n",
    "  age_buckets = tf.contrib.layers.bucketized_column(age,\n",
    "                                                    boundaries=[\n",
    "                                                        18, 25, 30, 35, 40, 45,\n",
    "                                                        50, 55, 60, 65\n",
    "                                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 이 곳에서는 나이를 5살 단위로 만들어 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Wide columns and deep columns.\n",
    "  wide_columns = [gender, native_country, education, occupation, workclass,\n",
    "                  relationship, age_buckets,\n",
    "                  tf.contrib.layers.crossed_column([education, occupation],\n",
    "                                                   hash_bucket_size=int(1e4)),\n",
    "                  tf.contrib.layers.crossed_column(\n",
    "                      [age_buckets, education, occupation],\n",
    "                      hash_bucket_size=int(1e6)),\n",
    "                  tf.contrib.layers.crossed_column([native_country, occupation],\n",
    "                                                   hash_bucket_size=int(1e4))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 위에서 만들어준 각 변수들을 배열에 넣어 줍니다.\n",
    "* crossed_column 컬럼이란 리니어 모델들은 독립적인 가중치를 각각의 특징에 할당하기 때문에 특정 조합의 상대적인 중요성을 알 수 없습니다. 여러 특징들이 있을 때 상관이 깊은 특징들을 연결을 해 주어 각각 크로스된 특징들을 하나의 특징 처럼 사용할 수 있게 해 줍니다. 그리하여 특징들간의 상호작용들을 효율적으로 저장할 수 있습니다.(위에도 썼는데, 직접 사용한 곳에서 한 번 더 설명...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "deep_columns = [\n",
    "      tf.contrib.layers.embedding_column(workclass, dimension=8),\n",
    "      tf.contrib.layers.embedding_column(education, dimension=8),\n",
    "      tf.contrib.layers.embedding_column(gender, dimension=8),\n",
    "      tf.contrib.layers.embedding_column(relationship, dimension=8),\n",
    "      tf.contrib.layers.embedding_column(native_country,\n",
    "                                         dimension=8),\n",
    "      tf.contrib.layers.embedding_column(occupation, dimension=8),\n",
    "      age,\n",
    "      education_num,\n",
    "      capital_gain,\n",
    "      capital_loss,\n",
    "      hours_per_week,\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 각각의 sparse, 고차원 카테고리적 특징들은 종종 embedding라 불리는 저차원이며 dense real-valued vector로 변환된다.\n",
    "* dimenstion는 embdding column의 차원인데, 8차원에서 4차원으로 테스트를 해 보았는데, 오히려 정확도가 더 높게 나왔네요. 평균치를 낼 정도로 많이 돌려 본 것은 아니지만요. 실제로 사용할 때는 여러 깊이로 테스트 해 보아야겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if model_type == \"wide\":\n",
    "    m = tf.contrib.learn.LinearClassifier(model_dir=model_dir,\n",
    "                                          feature_columns=wide_columns)\n",
    "  elif model_type == \"deep\":\n",
    "    m = tf.contrib.learn.DNNClassifier(model_dir=model_dir,\n",
    "                                       feature_columns=deep_columns,\n",
    "                                       hidden_units=[100, 50])\n",
    "  else:\n",
    "    m = tf.contrib.learn.DNNLinearCombinedClassifier(\n",
    "        model_dir=model_dir,\n",
    "        linear_feature_columns=wide_columns,\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=[100, 50]\n",
    "        # ,fix_global_step_increment_bug=True\n",
    "    )\n",
    "  return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 여기서는 model_type이 wide_n_deep 이므로 else: 부분을 타게 됩니다.\n",
    "* DNNLinearCombinedClassifier 는 wide와 deep 모델의 장점을 합친 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* input_fn은 train_and_eval에서 모델을 학습 시킬 때 input 값으로 들어가는 람다 함수 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def input_fn(df):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* CONTINUOUS_COLUMNS 에 들어있는 String 값을 하나씩 꺼내서 k로 가게 되고 key:value 형식의 데이터로 만들어 continuous_cols에 리턴 됩니다.\n",
    "* 이 곳에는 숫자형 데이터만 들어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categorical_cols = {\n",
    "      k: tf.SparseTensor(\n",
    "          indices=[[i, 0] for i in range(df[k].size)],\n",
    "          values=df[k].values,\n",
    "          dense_shape=[df[k].size, 1])\n",
    "      for k in CATEGORICAL_COLUMNS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 굉장히 복잡하게 생겼는데, 하나씩 보겠습니다.\n",
    "1. CATEGORICAL_COLUMNS는 스트링 형태의 데이터가 배열로 들어가 있는 값입니다.\n",
    "1. indices에 df크기의 배열 값이 들어간다.\n",
    "1. values에 df중 CATEGORICAL_COLUMNS 이름을 가진 값이 들어갑니다.\n",
    "1. 밀집도 모양은 df[k].size와 같습니다.\n",
    "1. 이 것들이 key:value 형식의 맵으로 categorical_cols에 값이 할당 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "  feature_cols = dict(continuous_cols)\n",
    "  feature_cols.update(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 두 개의 dict를 하나로 머지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "  label = tf.constant(df[LABEL_COLUMN].values)\n",
    "  return feature_cols, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* df의 라벨 값을 tensorflow 객체로 만들고, continuous_cols와 categorical_cols를 합친 dict를 리턴합니다.\n",
    "* 이 값은 모델에서 학습할 때 또는 테스트 할 때 사용됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
